\chapter{考察}
\label{chap_Discussion}

最大 load factor，メモリ使用量，挿入速度，探査速度，削除速度について考察する．
\leavevmode \newline

%
%\section{最大 load factor}
{\bf 最大 load factor}
\samepage\newline\indent
図\ref{fig_bench_LF}に示す，最大 load factor とテーブルサイズの関係について考察する．
{\bf std::unordered\_map} はテーブルサイズ $10^2$ 未満で load factor が低いものの，
区間 $10^2〜10^8$ において，高い load factor を示している．
{\bf sstd::CHashT} は区間 $10^1〜10^8$ に渡り 72.5 \% 以上を維持している．
{\bf sstd::IpCHashT (uint8, maxLF50)}，{\bf google::dense\_hash\_map}，{\bf ska::flat\_hash\_map} は，
load factor が制限されており，50 \% に留まっている．
{\bf sstd::IpCHashT (uint8, maxLF100)} は，テーブルサイズ $10^3$ 未満では 90 \% 以上の load factor を示す．
テーブルサイズが $4\times10^2$ を超える辺りから，linked list の長さが ``${\rm uint8} の最大値 - 1=254$'' に制限されている影響により，
load factor が単調に減少していく．
{\bf sstd::IpCHashT (uint16, maxLF100)} は区間 $10^1〜10^8$ に渡り 97.5 \% 以上を維持している．
なお，実際には 100 サンプルの中央値のため，
特に sstd::CHashT と sstd::IpCHashT (uint8, maxLF100) では，
特にテーブルサイズが $10^3$ 未満の場合において，ある程度揺らぎがある．
なお，sstd::IpCHashT の実装はいずれもパディングされる配列長を load factor の計算に加算している．
このため，{\bf sstd::IpCHashT (uint8, maxLF50)} では端数が発生し，丁度に 50 \% とはならない．
\leavevmode \newline

%
%\section{メモリ使用量}
{\bf メモリ使用量}
\samepage\newline\indent
図\ref{fig_bench_memory}に示す，メモリ使用量とテーブルサイズの関係について考察する．
複数のピークはリハッシュを示す．
ピークは幅を持っているが，これは測定間隔に等しく，実際には要素 1 つ分の幅しか持たない．
{\bf std::unordered\_map} は要素数にしたがって，ほぼ線形にメモリ使用量を増加させている．
これは，std::unordered\_map が要素ごとにメモリを確保することを示す．
また，リハッシュ時のピークも小さいことから，
アルゴリズムは ``Separate chaining with linked lists'' であると推察される．
{\bf sstd::IpCHashT (uint16, maxLF100)} は
殆どの区間で最も高いメモリ効率を示しており，
図\ref{fig_bench_LF}で示した最大 load factor の高さを反映する結果となった．
一部，他のハッシュテーブルとは異なるタイミングでリハッシュが発生しており，
load factor が 100 \% まで達していないことを示している．
{\bf google::dense\_hash\_map} は
load factor が 50 \% に制限されているにも関わらず，
std::unordered\_map 前後のメモリ使用量を示しており，
キーの一部を空符号や削除符号として使用することで，
メモリ効率を高める実装の特性が現れている．
{\bf sstd::CHashT}，{\bf sstd::IpCHashT (uint8, maxLF50)}，{\bf ska::flat\_hash\_map} は，
いずれもほぼ同じメモリ使用量を示している．
図\ref{fig_bench_LF}より，
{\bf sstd::CHashT} は区間 $10^1〜10^8$ に渡り 72.5 \% 以上の最大 load factor を維持しているものの，
ポインタによる singly linked list の構築には，1 要素あたり 8 Byte\footnote{64 bits CPU のため．} 必要としており，
多くのメモリを消費する結果となった．
Load factor の高い区間において，
メモリ使用量が増加しており，
ハッシュ先が衝突した分のメモリを動的に確保している．

\noindent
{\bf sstd::IpCHashT (uint8, maxLF50)}，{\bf ska::flat\_hash\_map} は
探査速度を得るため，単位要素あたり最も多くのメモリを消費しており，
std::unordered\_map と比較して 1.5 倍程度となる．
実利用に際しては，このメモリ使用量を許容できるかどうかが，
一つの課題となる．
{\bf sstd::IpCHashT (uint8, maxLF100)} は
sstd::IpCHashT (uint8, maxLF50) と sstd::IpCHashT (uint16, maxLF100) の
およそ中間でリハッシュする挙動を示している．

{\bf google::dense\_hash\_map}と{\bf sstd::IpCHashT (uint8, maxLF50)}，{\bf sstd::IpCHashT (uint16)}の
理論値なメモリ使用量と図\ref{fig_bench_memory}に示す実測値を比較する．
まず，{\bf google::dense\_hash\_map}は，
\begin{eqnarray*}
  {\rm memory\ size|_{type=dense\_hash\_map}} &=& ({\rm key\ size} + {\rm value\ size}) \times ({\rm elements} / {\rm max\ load\ factor}) {\rm\ [Byte]}\\
  &=& ({\rm uint64} + {\rm uint64}) \times ({\rm elements} / 0.5) {\rm\ [Byte]}\\
  &=& (8 + 8) \times ({\rm elements} / 0.5) {\rm\ [Byte]}\\
  &=& 32 \times {\rm elements} {\rm\ [Byte]}
\end{eqnarray*}
となる．
また，
コンパイラは配列アラインメントを大きい方に一致させるため，
sstd::IpCHashT の uint8 や uint16 は，next probe と prev probe を合わせて uint64 として確保される．
このため，{\bf sstd::IpCHashT (uint8, maxLF50)}は，
% アラインメントを考慮しない場合は下記．
%\begin{eqnarray*}
%  {\rm memory\ size|_{type=IpCHashT (uint8, maxLF50)}} &=& ({\rm key\ size} + {\rm value\ size} + {\rm next\ probe\ size} + {\rm prev\ probe\ size})\\
%                                              & & \times ({\rm elements} / {\rm max\ load\ factor}) {\rm\ [Byte]}\\
%  &=& ({\rm uint64} + {\rm uint64} + {\rm uint8} + {\rm uint8}) \times ({\rm elements} / 0.5) {\rm\ [Byte]}\\
%  &=& (8 + 8 + 1 + 1) \times ({\rm elements} / 0.5) {\rm\ [Byte]}\\
%  &=& 36 \times {\rm elements} {\rm\ [Byte]}
%\end{eqnarray*}
\begin{eqnarray*}
  {\rm memory\ size|_{type=IpCHashT (uint8, maxLF50)}} &=& ({\rm key\ size} + {\rm value\ size} + {\rm next\ probe\ size} + {\rm prev\ probe\ size})\\
                                              & & \times ({\rm elements} / {\rm max\ load\ factor}) {\rm\ [Byte]}\\
  &=& ({\rm uint64} + {\rm uint64} + {\rm uint8} + {\rm uint8}) \times ({\rm elements} / 0.5) {\rm\ [Byte]}\\
  &=& ({\rm uint64} + {\rm uint64} + {\rm uint64}) \times ({\rm elements} / 0.5) {\rm\ [Byte]}\\
  &=& (8 + 8 + 8) \times ({\rm elements} / 0.5) {\rm\ [Byte]}\\
  &=& 24 \times ({\rm elements} / 0.5) {\rm\ [Byte]}\\
  &=& 48 \times {\rm elements} {\rm\ [Byte]}
\end{eqnarray*}
となる．同様に {\bf sstd::IpCHashT (uint16, maxLF100)}は，
% アラインメントを考慮しない場合は下記．
%\begin{eqnarray*}
%  {\rm memory\ size|_{type=IpCHashT (uint16, maxLF100)}} &=& ({\rm key\ size} + {\rm value\ size} + {\rm next\ probe\ size} + {\rm prev\ probe\ size})\\
%                                               & & \times ({\rm elements} / {\rm max\ load\ factor}) {\rm\ [Byte]}\\
%  &=& ({\rm uint64} + {\rm uint64} + {\rm uint16} + {\rm uint16}) \times ({\rm elements} / 1.0) {\rm\ [Byte]}\\
%  &=& (8 + 8 + 2 + 2) \times {\rm elements} {\rm\ [Byte]}\\
%  &=& 20 \times {\rm elements} {\rm\ [Byte]}
%\end{eqnarray*}
\begin{eqnarray*}
  {\rm memory\ size|_{type=IpCHashT (uint16, maxLF100)}} &=& ({\rm key\ size} + {\rm value\ size} + {\rm next\ probe\ size} + {\rm prev\ probe\ size})\\
                                              & & \times ({\rm elements} / {\rm max\ load\ factor}) {\rm\ [Byte]}\\
  &=& ({\rm uint64} + {\rm uint64} + {\rm uint16} + {\rm uint16}) \times ({\rm elements} / 1.0) {\rm\ [Byte]}\\
  &=& ({\rm uint64} + {\rm uint64} + {\rm uint64}) \times ({\rm elements} / 1.0) {\rm\ [Byte]}\\
  &=& (8 + 8 + 8) \times {\rm elements} {\rm\ [Byte]}\\
  &=& 24 \times {\rm elements} {\rm\ [Byte]}
\end{eqnarray*}
となる．

{\bf google::dense\_hash\_map}と{\bf sstd::IpCHashT (uint8, maxLF50)}の理論比を考えると，
\begin{eqnarray*}
  \frac{32 \times {\rm elements} {\rm\ [Byte]}}{48 \times {\rm elements} {\rm\ [Byte]}}
  = \frac{2}{3}\approx& 0.67
\end{eqnarray*}
となる．
実測値は，図\ref{fig_bench_memory}より，要素数 $1.5\times 10^8$ のとき，8 GB と 12 GB であるから，
\begin{eqnarray*}
  \frac{8 {\rm\ [GByte]}}{12 {\rm\ [GByte]}}
  = \frac{2}{3}\approx& 0.67
\end{eqnarray*}
となる．したがって，理論値と実測値は一致する．

{\bf google::dense\_hash\_map}と{\bf sstd::IpCHashT (uint8, maxLF50)}の理論比を考えると，
\begin{eqnarray*}
  \frac{24 \times {\rm elements} {\rm\ [Byte]}}{32 \times {\rm elements} {\rm\ [Byte]}}
  = \frac{3}{4}= 0.75
\end{eqnarray*}
となる．実測値は，図\ref{fig_bench_memory}より，要素数 $1.5\times 10^8$ のとき，6 GB と 8 GB であるから，
\begin{eqnarray*}
  \frac{6 {\rm\ [GByte]}}{8 {\rm\ [GByte]}}
  = \frac{3}{4}= 0.75
\end{eqnarray*}
となる．したがって，理論値と実測値は一致する．


図\ref{fig_bench_memory_preAlloc}に示す，
ハッシュテーブルのサイズを $2\times10^8$ で初期化した場合の，
メモリ使用量とテーブルサイズの関係について考察する．
{\bf ska::flat\_hash\_map} は，
テーブルサイズを $2\times10^8$ より大きな最小の $2^k-1 (1,2,...)$ として初期化していおり，
$2^k-1|_{k=28} = 268435455$ としていることがわかる．
実際に，リハッシュ区間は $1.250\times10^8〜1.375\times10^8$ であり，
load factor が 50 \% となる要素数 $268435455/2=134217727.5$ を含んでいる．
一方で，
{\bf std::unordered\_map} や {\bf sstd::CHashT}，{\bf sstd::IpCHashTs}，{\bf google::dense\_hash\_map} は，
リハッシュせずに挿入可能な要素数が $2\times10^8$ となるように制御されている．
このとき，
図\ref{fig_bench_memory}と図\ref{fig_bench_memory_preAlloc}の比較から
{\bf sstd::CHashT}，{\bf sstd::IpCHashTs}，{\bf google::dense\_hash\_map} は
ほぼ倍の $2^k-1|_{k=29}$ に，
{\bf std::unordered\_map} は  $2^k-1|_{k=29}$ よりは小さいサイズに，それぞれ初期化されていると考えられる．
加えて，
{\bf sstd::CHashT} は，
テーブルサイズの増加に伴い，緩やかにメモリ使用量を増加させている．
このため，図\ref{fig_bench_memory} において，メモリ使用量の変化が折れ線に見えるのは，
メモリ使用量測定時の解像度不足と考えられる．
\leavevmode \newline

%
%\section{挿入速度}
{\bf 挿入速度}
\samepage\newline\indent
図\ref{fig_bench_insert_preAlloc}，\ref{fig_bench_insert_wRehash}，\ref{fig_bench_insert}に示す，挿入速度とテーブルサイズの関係について考察する．

図\ref{fig_bench_insert_preAlloc} は，
テーブルのメモリを事前に確保した場合の挿入速度の累積時間である．
ただし，図\ref{fig_bench_insert} のように，挿入速度はテーブルサイズに依存しており，
ここでは，$2.0\times10^8$ に初期化されたハッシュテーブルの速度を示す．
先の{\bf メモリ使用量}の項目で示した通り，
{\bf ska::flat\_hash\_map}は実テーブルサイズが $2.0\times10^8$ より大きな最小の $2^k-1\ (k=1,2,...)$ となるように，
それ以外のハッシュテーブルはリハッシュせずに挿入可能な要素数が $2.0\times10^8$ となるように，それぞれ制御されている．
まず，{\bf ska::flat\_hash\_map} は load factor が 50 \% を超えた時点でリハッシュしているとわかる．
$2.0\times10^8$ 要素挿入時の経過時間は，
概ね，
{\bf sstd::IpCHashT (uint8, maxLF50)}・{\bf sstd::IpCHashT (uint8, maxLF100)}・{\bf google::dense\_hash\_map}と，
{\bf sstd::IpCHashT (uint16, maxLF100)}・{\bf ska::flat\_hash\_map}と，
{\bf sstd::CHashT}と，
{\bf std::unordered\_map} に別れる．
挿入速度は，図\ref{fig_bench_insert}のようなテーブルサイズに依存するため，一概には言えないが，
{\bf sstd::IpCHashT (uint16, maxLF100)}では load factor の増加に従い，挿入に時間が掛かっている．
また，
{\bf sstd::CHashT}や，特に{\bf std::unordered\_map}は，堅調に時間が掛かっている．

図\ref{fig_bench_insert_wRehash} は，
テーブルサイズを 0 で初期化した場合の挿入速度の累積時間である．
図\ref{fig_bench_insert_preAlloc} と比較して，
{\bf sstd::CHashT} と {\bf sstd::IpCHashT (uint16, maxLF100)} の累積時間の増加が顕著である．
sstd::CHashT では，そもそもの挿入が遅い分リハッシュにも時間が掛かっている．
また，sstd::IpCHashT (uint16, maxLF100) では，load factor の増加に伴い，空き要素の線形走査に時間が掛かるためである．
なお，他の条件の sstd::IpCHashT は，比較的 load factor の低い領域を使用するため，線形走査の影響は軽微である．
{\bf std::unordered\_map} は，挿入とリハッシュの両方に時間が掛かっていることが伺える．
これは，{\bf sstd::CHashT}と同じ傾向である．
この中で，{\bf google::dense\_hash\_map} は最も高い性能を示した．
計算量の観点からは，
{\bf sstd::IpCHashT (uint8, maxLF50)}，{\bf sstd::IpCHashT (uint8, maxLF100)}，{\bf ska::flat\_hash\_map}，{\bf google::dense\_hash\_map} は
同程度のオーダーであると考えられる．

図\ref{fig_bench_insert} は，
テーブルサイズと挿入速度の関係である．
キャッシュの変わり目を除き，{\bf google::dense\_hash\_map}及び{\bf ska::flat\_hash\_map} が広い区間で高い性能を示している．
%{\bf google::dense\_hash\_map} は，L2 キャッシュに乗る区間 $10^2〜 10^5$ では，ska::flat\_hash\_map に次ぐ速度を示すものの，
%L3 キャッシュ外となる区間 $10^6〜 10^8$ では，sstd::IpCHashT (uint8, maxLF50) と入れ替わる結果となった．
{\bf sstd::IpCHashT (uint8, maxLF50)} は，
これに次ぐ性能を示しており，
複雑な挿入アルゴリズムの割に高速である．
これは，結局のところ，巨視的には挿入操作が単なる線形走査のためである．
しかしながら，{\bf sstd::IpCHashT (uint8, maxLF100)} と {\bf sstd::IpCHashT (uint16, maxLF100)} の示す通り，
線形走査による空き領域の探査は load factor の高い領域において大きく効率を落としている．
{\bf sstd::CHashT} は L2，L3 キャッシュの外へ格納が増えるにしたがい，大きく速度を落としている．
\leavevmode \newline

%
%\section{探査速度}
{\bf 探査速度}
\samepage\newline\indent
図
\ref{fig_bench_find_s_sm}，\ref{fig_bench_find_s_um}，
\ref{fig_bench_find_us_sm}，\ref{fig_bench_find_us_um}に示す，
探査速度とテーブルサイズの関係について考察する．

%%%
まず，successful search の速度，図\ref{fig_bench_find_s_sm}，\ref{fig_bench_find_s_um}について考察する．

Successful major option をコンパイル時に IpCHashT へ指定した速度は，図\ref{fig_bench_find_s_sm} である．
{\bf sstd::IpCHashT (uint8, maxLF50)} は，
L2 キャッシュから溢れるテーブルサイズ $10^5$ 前後を除き，
区間 $10^2〜10^7$ の殆どに渡り最速の探査性能を示す．
{\bf sstd::IpCHashT (uint16, maxLF100)} は図\ref{fig_bench_memory} に示すように
google::dense\_hash\_map の 75 \% のメモリ使用量であるにも関わらず，
L3 キャッシュ内から CPU キャッシュ外の区間 $1.5\times10^5〜3.5\times10^7$ において，
同程度の速度を保持している．
ただし，L2 キャッシュ内の区間 $1.0\times10^1〜1.5\times10^5$ と
非常にテーブルサイズの大きな区間 $3.5\times10^7〜2.0\times10^8$ においては
google::dense\_hash\_map の方が高速に動作している．

Unsuccessful major option をコンパイル時に IpCHashT へ指定した速度は，図\ref{fig_bench_find_s_um} である．
{\bf sstd::IpCHashT (uint8, maxLF50)} は，
L2 キャッシュから溢れるテーブルサイズ $10^5$ 前後を除き，
区間 $10^2〜10^7$ の殆どに渡り 1\textasciitilde 2 番目の探査速度を保持している．
一方で，その他のオプションの sstd::IpCHashT は，優位性のある速度に達していない．

%%%
次に，unuccessful search の速度，図\ref{fig_bench_find_us_sm}，\ref{fig_bench_find_us_um}について考察する．

Successful major option をコンパイル時に IpCHashT へ指定した速度は，図\ref{fig_bench_find_us_sm} である．
{\bf sstd::IpCHashT (uint8, maxLF50)} は，
区間 $1.0\times10^2〜1.5\times10^5$ において高速に動作するが，
区間 $1.5\times10^5〜1.5\times10^7$ においては {\bf ska::flat\_hash\_map} が最速である．
区間 $1.5\times10^7〜2.0\times10^8$ においては，よりメモリ効率の高い
{\bf sstd::IpCHashT (uint8, maxLF100)} や {\bf sstd::IpCHashT (uint16, maxLF100)} が最速である．
なお，図\ref{fig_taocp_v3_fig44} (a) に示すように，Separate Chaining はアルゴリズム上 unsuccessful search に強く，
一部区間では {\bf sstd::CHashT} であっても google::dense\_hash\_map を上回る速度を示している．

Unsuccessful major option をコンパイル時に IpCHashT へ指定した速度は，図\ref{fig_bench_find_us_um} である．
{\bf sstd::IpCHashT (uint8, maxLF50)} は，
特に L1, L2 キャッシュに収まる区間 $1.0\times10^2〜1.5\times10^5$ において，
google::dense\_hash\_map の \textasciitilde4 倍程度高速に動作している．
また，
区間 $1.5\times10^5〜1.5\times10^7$ でも \textasciitilde3 倍程度高速に動作している．
一方で，
区間 $1.5\times10^7〜2.0\times10^8$ においては，よりメモリ効率の高い {\bf sstd::IpCHashT (uint16, maxLF100)} が速度を伸ばした．
図\ref{fig_bench_find_us_um}の結果は特に，Chaining 系のアルゴリズムが高速に動作する結果となった．
\leavevmode \newline

%
%\section{削除速度}
{\bf 削除速度}
\samepage\newline\indent
図\ref{fig_bench_erase_sm}，\ref{fig_bench_erase_um}に示す，削除速度とテーブルサイズの関係について考察する．

まず，速度の違いについて，
successful major option を指定した場合と，
unsuccessful major option を指定した場合の違いについて考察する．
このベンチマークでは，存在する key-value ペアを削除しているため，
図\ref{fig_bench_erase_sm}に示す successful search を優先する設定が，
図\ref{fig_bench_erase_um}に示す unsuccessful search を優先する設定より高速に処理すると期待されたが，
明白な違いは認められなかった．
これは，単に計算量がオーダーで異なるため，
違いが埋もれていると考えられる．

{\bf google::dense\_hash\_map} は，
区間 $1.0\times10^1〜2.0\times10^8$ のほぼ全てにおいて最速を保持している．
{\bf sstd::IpCHashT (uint8, maxLF50)} は，
L2 キャッシュ内の区間 $2.0\times10^2〜1.5\times10^5$ において，
ska::flat\_hash\_map より高速に動作するものの，
区間 $1.5\times10^2〜2.0\times10^8$ においては，
{\bf ska::flat\_hash\_map} の方が高速に動作している．
%\leavevmode \newline


